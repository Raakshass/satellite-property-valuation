# ğŸ›°ï¸ Satellite Imagery-Based Property Valuation

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Complete-success.svg)]()

> **Multimodal Deep Learning for Real Estate Price Prediction using Satellite Imagery and Tabular Features**

---

## ğŸ“‹ Executive Summary

This project implements a **Multimodal Regression Pipeline** to predict residential property values by synthesizing tabular housing data with high-resolution satellite imagery. By leveraging **Late Fusion Deep Learning** architectures, the model captures non-quantifiable environmental factorsâ€”such as "curb appeal," vegetation density, and neighborhood layoutâ€”that traditional hedonic pricing models miss.

### Key Achievements
- ğŸ¯ **21,613 properties** analyzed with satellite imagery
- ğŸ“Š **Validation RÂ² Score**: 0.8413
- ğŸ” **RMSE**: $138,039
- ğŸ§  **Explainability**: Grad-CAM attention visualization
- ğŸ† **Outperforms** on luxury properties (>$1.2M)

---

## ğŸ—ï¸ System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT DATA SOURCES â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Satellite Image â”‚ Tabular Features â”‚
â”‚ (224Ã—224Ã—3 RGB) â”‚ (35 dimensions) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚
â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visual Encoder â”‚ â”‚ Tabular Encoder â”‚
â”‚ (ResNet18 CNN) â”‚ â”‚ (MLP) â”‚
â”‚ â†’ 256D embedding â”‚ â”‚ â†’ 128D embedding â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Late Fusion â”‚
â”‚ (384D vector) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Regression Head â”‚
â”‚ (Dense Layers) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–¼
```

### Component Details

#### 1. **Visual Encoder (CNN Branch)**
- **Backbone**: ResNet18 (pretrained on ImageNet)
- **Input**: 224Ã—224Ã—3 RGB satellite images
- **Output**: 256-dimensional visual embedding
- **Purpose**: Extracts spatial hierarchies and environmental context (water bodies, vegetation, building density)

#### 2. **Tabular Encoder (MLP Branch)**
- **Input**: 35 normalized numerical features
  - Physical: `sqft_living`, `bedrooms`, `bathrooms`
  - Location: `lat`, `long`, `zipcode`
  - Quality: `grade`, `condition`, `view`
  - Engineered: `luxury_index`, `location_cluster`, `sqft_ratios`
- **Output**: 128-dimensional tabular embedding
- **Architecture**: 35 â†’ 128 â†’ 128 with Dropout(0.3)

#### 3. **Late Fusion Head**
- **Input**: Concatenated embeddings (256D visual + 128D tabular = 384D)
- **Architecture**: 384 â†’ 256 â†’ 128 â†’ 1
- **Regularization**: Dropout(0.3) on dense layers
- **Output**: Log-transformed property price

---

## ğŸ“Š Performance Metrics

| Model Architecture | RÂ² Score | RMSE (USD) | MAE (USD) | Inference Time | Validation Strategy |
|-------------------|----------|------------|-----------|----------------|---------------------|
| **XGBoost Baseline** (Tabular Only) | **0.8849** | $117,540 | $84,320 | 5 ms | 85/15 Split |
| **Multimodal CNN** (Image + Tabular) | **0.8413** | $138,039 | $95,210 | 180 ms | 85/15 Split |

### Performance by Price Segment

| Price Range | XGBoost RÂ² | Multimodal RÂ² | Advantage |
|-------------|-----------|---------------|-----------|
| <$300K | 0.89 | 0.84 | -0.05 |
| $300K-$600K | 0.88 | 0.85 | -0.03 |
| $600K-$900K | 0.87 | 0.86 | -0.01 |
| $900K-$1.2M | 0.86 | **0.87** | âœ… **+0.01** |
| >$1.2M | 0.83 | **0.85** | âœ… **+0.02** |

**Key Insight**: Multimodal CNN outperforms on **luxury properties** where visual features (waterfront, landscaping) are critical valuation signals.

---

## ğŸ” Explainability (Grad-CAM)

To ensure model transparency, **Gradient-weighted Class Activation Mapping (Grad-CAM)** was implemented on the final convolutional layer of the visual encoder.

### Attention Patterns

#### High-Value Properties (>$1.2M)
- ğŸŒŠ **Water bodies**: Strongest attention (red heatmap)
- ğŸŒ³ **Green spaces**: Secondary focus (orange heatmap)
- ğŸ¡ **Building footprint**: Tertiary signal (yellow heatmap)

#### Low-Value Properties (<$300K)
- ğŸ™ï¸ **Building density**: Dominant attention (cyan heatmap)
- ğŸš— **Roads/concrete**: High attention (light cyan)
- ğŸŒ± **Minimal vegetation**: Low attention (blue heatmap)

![Grad-CAM Visualization](outputs/gradcam_visualization.png)

### Quantitative Visual Metrics
- **Green Space Premium**: +$180,000 per 10% coverage increase
- **Building Density Penalty**: -$95,000 per 10% density increase
- **Waterfront Effect**: +$320,000 average premium

---

## ğŸ“‚ Repository Structure
```
satellite-property-valuation/
â”œâ”€â”€ ğŸ“ data/
â”‚ â”œâ”€â”€ images/ # Satellite imagery dataset (Train/Test)
â”‚ â”œâ”€â”€ processed/ # Scaled feature matrices and scaler objects
â”‚ â””â”€â”€ raw/ # Original tabular datasets (kc_house_data.csv)
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb # EDA and geospatial analysis
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb # Feature extraction and transformation
â”‚ â”œâ”€â”€ 03_baseline_models.ipynb # XGBoost baseline
â”‚ â”œâ”€â”€ 04_multimodal_cnn_training.ipynb # Deep Learning training loop
â”‚ â””â”€â”€ 05_evaluation_and_explainability.ipynb # Inference and Grad-CAM
â”‚
â”œâ”€â”€ ğŸ“Š outputs/
â”‚ â”œâ”€â”€ models/ # Serialized model weights (.pth, .pkl)
â”‚ â”œâ”€â”€ predictions/ # Final submission files (multimodal_submission.csv)
â”‚ â”œâ”€â”€ architecture_diagram.md
â”‚ â”œâ”€â”€ gradcam_visualization.png
â”‚ â””â”€â”€ training_history.png
â”‚
â”œâ”€â”€ ğŸ src/
â”‚ â”œâ”€â”€ data_fetcher.py # Async image acquisition pipeline (Mapbox API)
â”‚ â””â”€â”€ test_fetcher.py # Unit tests for data fetcher
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt # Python dependencies
â”œâ”€â”€ ğŸ“ README.md # This file
â””â”€â”€ ğŸš« .gitignore # Git exclusions
```

---

## ğŸš€ Installation and Usage

### 1. Environment Setup

```
# Clone the repository
git clone https://github.com/Raakshass/satellite-property-valuation.git
cd satellite-property-valuation

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```
2. Data Acquisition
Execute the data fetcher to populate the image directory using the Mapbox Static Images API:

bash
python src/data_fetcher.py
Note: You'll need a Mapbox API token. Sign up at mapbox.com and add your token to the script.

3. Pipeline Execution
Run the Jupyter notebooks in sequential order:

bash
jupyter notebook
Execute notebooks 01 through 05 to replicate:

EDA and geospatial analysis

Feature engineering (luxury index, location clusters)

Baseline modeling (XGBoost)

Multimodal training (ResNet18 + MLP fusion)

Evaluation and Grad-CAM visualization

4. Model Training
python
# Quick training example
from src.model import MultimodalRealEstateNet
import torch

model = MultimodalRealEstateNet()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
criterion = torch.nn.MSELoss()

# Training loop (see notebook 04 for full implementation)
for epoch in range(15):
    train_loss = train_epoch(model, train_loader, optimizer, criterion)
    val_loss = validate(model, val_loader, criterion)
ğŸ› ï¸ Tech Stack
Category	Technologies
Deep Learning	PyTorch 2.0, torchvision, ResNet18
Machine Learning	Scikit-learn, XGBoost, LightGBM
Data Processing	Pandas, NumPy, GeoPandas
Computer Vision	OpenCV, PIL, Grad-CAM
Visualization	Matplotlib, Seaborn, Plotly
API Integration	Mapbox Static Images API, AsyncIO
Environment	Jupyter Notebooks, Python 3.10+
ğŸ“ˆ Training Dynamics
Training History

Best Epoch: 6 (early stopping triggered)

Training Strategy: AdamW optimizer, MSE loss, learning rate 1e-4

Convergence: Validation loss plateaus at epoch 6

Overfitting Prevention: Dropout(0.3), early stopping patience=5

ğŸ¯ Key Findings
1. Visual Data Contains Predictive Signal
Satellite imagery captures environmental quality (green space, water proximity, density) that correlates with property prices. The model achieves 84.13% RÂ², validating that visual data is statistically significant.

2. Environmental Factors Drive High-End Valuations
Multimodal CNN achieves +0.02 RÂ² advantage on luxury homes (>$1.2M). Grad-CAM analysis confirms the model correctly identifies water access, green space, and low density as value drivers.

3. Trade-off: Accuracy vs. Interpretability
While XGBoost achieves higher raw accuracy (0.8849 vs 0.8413), the Multimodal CNN provides:

âœ… Visual explainability (Grad-CAM heatmaps)

âœ… Client trust (transparent reasoning)

âœ… Regulatory compliance (auditable decisions)

âœ… Superior luxury performance (where it matters most)

ğŸ“š Documentation
Full Technical Report: FULL_PROJECT_REPORT.pdf

Architecture Diagram: architecture_diagram.md

Dataset Source: King County House Sales

ğŸ“ Authors
Data Science Team
Indian Institute of Technology Roorkee
Submitted for: Data Science Problem Statement 2026

ğŸ“„ License
This project is licensed under the MIT License - see LICENSE file for details.

ğŸ™ Acknowledgments
Mapbox for providing satellite imagery API

PyTorch Team for the deep learning framework

King County Open Data for the housing dataset

ResNet Authors (He et al., 2016) for transfer learning architecture

Grad-CAM Authors (Selvaraju et al., 2017) for explainability framework

ğŸ“ Contact
For questions or collaborations:

GitHub: @Raakshass

Repository: satellite-property-valuation

<div align="center">
â­ Star this repository if you find it useful!


